{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. A/B Testing Simulation: Naive vs Smart\n",
    "\n",
    "## Objective\n",
    "To quantify the \"Efficiency Gain\" of our **Smart (Unmet Demand)** algorithm against a **Population-Weighted Baseline**.\n",
    "This simulates the impact of investing in *N* chargers under both strategies.\n",
    "\n",
    "## Scenarios\n",
    "1.  **Scenario A (Baseline):** Distribute *N* chargers proportional to **Vehicle Density** (Population Weighted). This mimics a standard policy approach.\n",
    "2.  **Scenario B (Smart):** Use Weighted K-Means on **Unmet_Demand** to place *N* chargers. This targets underserved high-demand areas.\n",
    "\n",
    "## Metrics\n",
    "*   **EV Population Served (Weighted):** For each charger, create a 500m buffer; for each barrio, compute the % of its area covered by any buffer (max across chargers) and count `EV_Count` weighted by that %.\n",
    "*   **Unmet Demand Covered (Weighted):** Same coverage logic applied to `Unmet_Demand`.\n",
    "*   **Coverage Efficiency:** `ev_population_served / total_city_evs`.\n",
    "*   **Efficiency Gain:** % Improvement of Smart over Baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 73 neighborhoods.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_92080\\1666039808.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['centroid'] = gdf.geometry.centroid\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_92080\\1666039808.py:19: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['lat'] = gdf.centroid.y\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_92080\\1666039808.py:20: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf['lng'] = gdf.centroid.x\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd",
    "import geopandas as gpd",
    "import numpy as np",
    "from sklearn.cluster import KMeans",
    "from shapely.geometry import Point",
    "import random",
    "import matplotlib.pyplot as plt",
    "import os",
    "",
    "# 1. Load Data",
    "DATA_PATH = '../data/processed/barrios_with_demand.geojson'",
    "if not os.path.exists(DATA_PATH):",
    "    DATA_PATH = 'data/processed/barrios_with_demand.geojson'",
    "",
    "gdf = gpd.read_file(DATA_PATH)",
    "",
    "# Calculate Centroids with proper CRS transformation (Fix for CRS warning)",
    "# EPSG:25831 is ETRS89 / UTM zone 31N (Barcelona, Spain) - uses meters",
    "# This ensures accurate centroid calculations, then we convert back to lat/lon",
    "",
    "# Convert to projected CRS (EPSG:25831) for accurate centroid calculation",
    "gdf_projected = gdf.to_crs('EPSG:25831')",
    "",
    "# Calculate centroids in projected CRS",
    "centroids_projected = gdf_projected.geometry.centroid",
    "",
    "# Convert centroids back to EPSG:4326 (lat/lon) for use in algorithms",
    "centroids_gdf = gpd.GeoDataFrame(geometry=centroids_projected, crs='EPSG:25831')",
    "centroids_4326 = centroids_gdf.to_crs('EPSG:4326')",
    "",
    "# Extract lat/lng coordinates",
    "gdf['lat'] = centroids_4326.geometry.y",
    "gdf['lng'] = centroids_4326.geometry.x",
    "",
    "# Recalculate Unmet Demand logic here to be self-contained",
    "from sklearn.preprocessing import MinMaxScaler",
    "scaler = MinMaxScaler()",
    "gdf['Norm_Supply'] = scaler.fit_transform(gdf[['Charger_Count']].fillna(0))",
    "SUPPLY_IMPACT = 80 ",
    "gdf['Unmet_Demand'] = gdf['Demand_Score'] - (gdf['Norm_Supply'] * SUPPLY_IMPACT)",
    "gdf['Unmet_Demand'] = gdf['Unmet_Demand'].clip(lower=0)",
    "",
    "print(f\"Loaded {len(gdf)} neighborhoods.\")",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Simulation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population_weighted_locations(n, gdf, rng=None, py_rng=None):\n",
    "    \"\"\"\n",
    "    Generates N locations distributed proportionally to Vehicle Density.\n",
    "    This mimics a 'Standard Policy' approach (more cars = more chargers).\n",
    "\n",
    "    Parameters\n",
    "    - rng: numpy Generator (for reproducible barrio sampling)\n",
    "    - py_rng: python random.Random (for reproducible point placement inside polygons)\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    if py_rng is None:\n",
    "        py_rng = random.Random()\n",
    "\n",
    "    points = []\n",
    "    \n",
    "    # 1. Select Neighborhoods weighted by Total Vehicles\n",
    "    # Handle NaNs in weights\n",
    "    weights = gdf['Total_Vehicles'].fillna(0)\n",
    "    # Normalize weights to sum to 1\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    # Sample n neighborhoods (indexes) with replacement\n",
    "    sampled_indices = rng.choice(gdf.index.to_numpy(), size=n, replace=True, p=weights.to_numpy())\n",
    "    \n",
    "    # 2. Place a random point in each selected neighborhood\n",
    "    for idx in sampled_indices:\n",
    "        poly = gdf.loc[idx, 'geometry']\n",
    "        min_x, min_y, max_x, max_y = poly.bounds\n",
    "        \n",
    "        while True:\n",
    "            rand_x = py_rng.uniform(min_x, max_x)\n",
    "            rand_y = py_rng.uniform(min_y, max_y)\n",
    "            p = Point(rand_x, rand_y)\n",
    "            if poly.contains(p):\n",
    "                points.append([p.y, p.x]) # Lat, Lng\n",
    "                break\n",
    "                \n",
    "    return np.array(points)\n",
    "\n",
    "def generate_smart_locations(n, df_features, weights):\n",
    "    \"\"\"Runs Weighted K-Means to find optimal locations.\"\"\"\n",
    "    # Safety Check: Cannot request more clusters than data points (neighborhoods)\n",
    "    n_samples = len(df_features)\n",
    "    n_clusters = n\n",
    "    if n > n_samples:\n",
    "        print(f\"Warning: Requested {n} hubs but only {n_samples} neighborhoods available. Capping optimization at {n_samples}.\")\n",
    "        n_clusters = n_samples\n",
    "        \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    kmeans.fit(df_features, sample_weight=weights)\n",
    "    return kmeans.cluster_centers_\n",
    "\n",
    "def evaluate_coverage(locations, gdf_target, radius_m=500):\n",
    "    \"\"\"\n",
    "    Improved evaluation using *EVs only* and a realistic coverage radius.\n",
    "\n",
    "    What this does (high level):\n",
    "    - Creates a buffer (default 500m) around each proposed charger location\n",
    "    - Finds which barrios (neighborhood polygons) intersect each buffer\n",
    "    - Computes the % of each barrio's area covered by the buffer\n",
    "    - Counts EVs proportionally to that coverage %\n",
    "    - De-duplicates barrios across multiple chargers (keeps the best coverage %)\n",
    "\n",
    "    Notes:\n",
    "    - We reproject geometries to a metric CRS (EPSG:3857) so that the buffer\n",
    "      radius is in meters. No extra libraries required beyond GeoPandas/Shapely.\n",
    "    - `radius_m` is configurable to support sensitivity analysis.\n",
    "    \"\"\"\n",
    "    if len(locations) == 0:\n",
    "        total_evs_city = float(gdf_target['EV_Count'].fillna(0).sum())\n",
    "        return {\n",
    "            'served_barrios_count': 0,\n",
    "            'ev_population_served': 0.0,\n",
    "            'unmet_demand_captured': 0.0,\n",
    "            'coverage_efficiency': 0.0 if total_evs_city == 0 else 0.0\n",
    "        }\n",
    "\n",
    "    # --- 1) Prepare barrio polygons in a metric CRS (meters) ---\n",
    "    barrios = gdf_target[['Barri_ID', 'EV_Count', 'Unmet_Demand', 'geometry']].copy()\n",
    "    # EPSG:3857 is a common meter-based CRS suitable for ~city-scale buffers.\n",
    "    barrios_m = barrios.to_crs(epsg=3857)\n",
    "    barrio_area = barrios_m.geometry.area\n",
    "    # Avoid division by zero (shouldn't happen, but keep robust).\n",
    "    barrio_area = barrio_area.replace(0, np.nan)\n",
    "\n",
    "    # --- 2) Build point buffers around charger locations (also in meters) ---\n",
    "    loc_df = pd.DataFrame(locations, columns=['lat', 'lng'])\n",
    "    loc_gdf = gpd.GeoDataFrame(\n",
    "        loc_df,\n",
    "        geometry=gpd.points_from_xy(loc_df.lng, loc_df.lat),\n",
    "        crs=gdf_target.crs\n",
    "    )\n",
    "    loc_m = loc_gdf.to_crs(epsg=3857)\n",
    "    buffers = loc_m.geometry.buffer(radius_m)\n",
    "\n",
    "    # --- 3) Compute best (max) coverage % per barrio across all buffers ---\n",
    "    max_coverage = np.zeros(len(barrios_m), dtype=float)\n",
    "\n",
    "    # With ~73 barrios and <=50 chargers, this loop is fast and easy to reason about.\n",
    "    for buf in buffers:\n",
    "        # Intersection area for every barrio with this buffer\n",
    "        inter_area = barrios_m.geometry.intersection(buf).area\n",
    "        coverage_pct = (inter_area / barrio_area).fillna(0).clip(lower=0, upper=1).to_numpy()\n",
    "        max_coverage = np.maximum(max_coverage, coverage_pct)\n",
    "\n",
    "    served_mask = max_coverage > 0\n",
    "    served_barrios_count = int(served_mask.sum())\n",
    "\n",
    "    # --- 4) Compute EVs served (weighted by coverage %) ---\n",
    "    ev_counts = barrios['EV_Count'].fillna(0).to_numpy(dtype=float)\n",
    "    ev_population_served = float((ev_counts * max_coverage).sum())\n",
    "\n",
    "    # Keep Unmet Demand logic consistent with the new coverage model by weighting it too\n",
    "    # (partial barrio coverage captures partial unmet demand).\n",
    "    unmet_vals = barrios['Unmet_Demand'].fillna(0).to_numpy(dtype=float)\n",
    "    unmet_demand_captured = float((unmet_vals * max_coverage).sum())\n",
    "\n",
    "    # --- 5) Coverage efficiency: EVs served / total EVs in the city ---\n",
    "    total_evs_city = float(barrios['EV_Count'].fillna(0).sum())\n",
    "    coverage_efficiency = 0.0 if total_evs_city == 0 else float(ev_population_served / total_evs_city)\n",
    "\n",
    "    return {\n",
    "        'served_barrios_count': served_barrios_count,\n",
    "        'ev_population_served': ev_population_served,\n",
    "        'unmet_demand_captured': unmet_demand_captured,\n",
    "        'coverage_efficiency': coverage_efficiency\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Simulation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Simulating N=10 --- \n",
      "--- Simulating N=25 --- \n",
      "--- Simulating N=50 --- \n",
      "Simulation Complete.\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "SCENARIOS = [10, 25, 50] # Adjusted to stay safely under 73 limit\n",
    "\n",
    "# Baseline is stochastic (random). To make results reliable, we run multiple\n",
    "# iterations and summarize the distribution (mean + percentiles).\n",
    "BASELINE_ITERATIONS = 300\n",
    "BASELINE_SEED = 42\n",
    "\n",
    "# Coverage radius (meters) used by evaluate_coverage()\n",
    "RADIUS_M = 500\n",
    "\n",
    "results = []\n",
    "locations_export = []\n",
    "\n",
    "X_coords = gdf[['lat', 'lng']].values\n",
    "W_weights = gdf['Unmet_Demand'].fillna(0).values\n",
    "\n",
    "def _pct(arr, q):\n",
    "    \"\"\"Helper for percentiles with numpy arrays.\"\"\"\n",
    "    return float(np.percentile(arr, q)) if len(arr) else float('nan')\n",
    "\n",
    "for n in SCENARIOS:\n",
    "    print(f\"--- Simulating N={n} --- \")\n",
    "    \n",
    "    # ------------------------------------------------------------\n",
    "    # 1) Baseline (Population Weighted) with ITERATIONS\n",
    "    # ------------------------------------------------------------\n",
    "    # Export ONE representative baseline layout for mapping (stable seed).\n",
    "    rng_map = np.random.default_rng(BASELINE_SEED + n)\n",
    "    py_rng_map = random.Random(BASELINE_SEED + n)\n",
    "    base_locs = generate_population_weighted_locations(n, gdf, rng=rng_map, py_rng=py_rng_map)\n",
    "    \n",
    "    # Run many baseline iterations for robust KPIs\n",
    "    baseline_metrics = []\n",
    "    for it in range(BASELINE_ITERATIONS):\n",
    "        # Different seeds per iteration for reproducible stochastic baseline distribution\n",
    "        seed_it = (BASELINE_SEED * 1_000_000) + (n * 10_000) + it\n",
    "        rng_it = np.random.default_rng(seed_it)\n",
    "        py_rng_it = random.Random(seed_it)\n",
    "        locs_it = generate_population_weighted_locations(n, gdf, rng=rng_it, py_rng=py_rng_it)\n",
    "        baseline_metrics.append(evaluate_coverage(locs_it, gdf, radius_m=RADIUS_M))\n",
    "\n",
    "    # Convert baseline distribution to arrays\n",
    "    base_served = np.array([m['served_barrios_count'] for m in baseline_metrics], dtype=float)\n",
    "    base_ev = np.array([m['ev_population_served'] for m in baseline_metrics], dtype=float)\n",
    "    base_unmet = np.array([m['unmet_demand_captured'] for m in baseline_metrics], dtype=float)\n",
    "    base_eff = np.array([m['coverage_efficiency'] for m in baseline_metrics], dtype=float)\n",
    "\n",
    "    base_summary = {\n",
    "        # Use MEAN as the main baseline KPI point estimate\n",
    "        'served_barrios_count': float(base_served.mean()),\n",
    "        'ev_population_served': float(base_ev.mean()),\n",
    "        'unmet_demand_captured': float(base_unmet.mean()),\n",
    "        'coverage_efficiency': float(base_eff.mean()),\n",
    "        # Extra distribution columns (useful for Tableau bands / uncertainty)\n",
    "        'baseline_iterations': int(BASELINE_ITERATIONS),\n",
    "        'ev_population_served_p05': _pct(base_ev, 5),\n",
    "        'ev_population_served_p50': _pct(base_ev, 50),\n",
    "        'ev_population_served_p95': _pct(base_ev, 95),\n",
    "        'unmet_demand_captured_p05': _pct(base_unmet, 5),\n",
    "        'unmet_demand_captured_p50': _pct(base_unmet, 50),\n",
    "        'unmet_demand_captured_p95': _pct(base_unmet, 95),\n",
    "        'coverage_efficiency_p05': _pct(base_eff, 5),\n",
    "        'coverage_efficiency_p50': _pct(base_eff, 50),\n",
    "        'coverage_efficiency_p95': _pct(base_eff, 95),\n",
    "    }\n",
    "\n",
    "    results.append({\n",
    "        'N_Chargers': n,\n",
    "        'Strategy': 'Baseline',\n",
    "        **base_summary\n",
    "    })\n",
    "    \n",
    "    # Add representative Baseline locations to Export List (for maps)\n",
    "    for i, loc in enumerate(base_locs):\n",
    "        locations_export.append({\n",
    "            'Scenario_ID': f'Baseline_{n}',\n",
    "            'Type': 'Baseline',\n",
    "            'N_Chargers': n,\n",
    "            'Lat': loc[0],\n",
    "            'Lng': loc[1],\n",
    "            'Hub_ID': i+1\n",
    "        })\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2) Smart (Unmet Demand) - deterministic (random_state fixed)\n",
    "    # ------------------------------------------------------------\n",
    "    smart_locs = generate_smart_locations(n, X_coords, W_weights)\n",
    "    smart_metrics = evaluate_coverage(smart_locs, gdf, radius_m=RADIUS_M)\n",
    "\n",
    "    # How often does Smart beat a random Baseline draw?\n",
    "    ev_win_rate = float((smart_metrics['ev_population_served'] > base_ev).mean())\n",
    "    unmet_win_rate = float((smart_metrics['unmet_demand_captured'] > base_unmet).mean())\n",
    "    eff_win_rate = float((smart_metrics['coverage_efficiency'] > base_eff).mean())\n",
    "\n",
    "    results.append({\n",
    "        'N_Chargers': n,\n",
    "        'Strategy': 'Smart',\n",
    "        **smart_metrics,\n",
    "        'baseline_iterations': int(BASELINE_ITERATIONS),\n",
    "        'ev_win_rate_vs_baseline': ev_win_rate,\n",
    "        'unmet_win_rate_vs_baseline': unmet_win_rate,\n",
    "        'eff_win_rate_vs_baseline': eff_win_rate,\n",
    "        'baseline_ev_mean': float(base_ev.mean()),\n",
    "        'baseline_ev_p05': _pct(base_ev, 5),\n",
    "        'baseline_ev_p50': _pct(base_ev, 50),\n",
    "        'baseline_ev_p95': _pct(base_ev, 95),\n",
    "    })\n",
    "    \n",
    "    # Add Smart locations to Export List\n",
    "    for i, loc in enumerate(smart_locs):\n",
    "        locations_export.append({\n",
    "            'Scenario_ID': f'Smart_{n}',\n",
    "            'Type': 'Smart',\n",
    "            'N_Chargers': n,\n",
    "            'Lat': loc[0],\n",
    "            'Lng': loc[1],\n",
    "            'Hub_ID': i+1\n",
    "        })\n",
    "    \n",
    "print(\"Simulation Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and KPI Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ev_population_served</th>\n",
       "      <th colspan=\"2\" halign=\"left\">unmet_demand_captured</th>\n",
       "      <th colspan=\"2\" halign=\"left\">coverage_efficiency</th>\n",
       "      <th>EV_Pop_Gain_Pct</th>\n",
       "      <th>Demand_Gain_Pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strategy</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Smart</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Smart</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Smart</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Chargers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4465.551693</td>\n",
       "      <td>4991.302048</td>\n",
       "      <td>95.843969</td>\n",
       "      <td>118.285899</td>\n",
       "      <td>0.059217</td>\n",
       "      <td>0.066189</td>\n",
       "      <td>11.773469</td>\n",
       "      <td>23.415068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9187.245127</td>\n",
       "      <td>13399.695157</td>\n",
       "      <td>199.763724</td>\n",
       "      <td>311.259376</td>\n",
       "      <td>0.121831</td>\n",
       "      <td>0.177691</td>\n",
       "      <td>45.851068</td>\n",
       "      <td>55.813763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>14245.151587</td>\n",
       "      <td>22575.719942</td>\n",
       "      <td>311.278521</td>\n",
       "      <td>536.529363</td>\n",
       "      <td>0.188903</td>\n",
       "      <td>0.299373</td>\n",
       "      <td>58.480026</td>\n",
       "      <td>72.363118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ev_population_served               unmet_demand_captured  \\\n",
       "Strategy               Baseline         Smart              Baseline   \n",
       "N_Chargers                                                            \n",
       "10                  4465.551693   4991.302048             95.843969   \n",
       "25                  9187.245127  13399.695157            199.763724   \n",
       "50                 14245.151587  22575.719942            311.278521   \n",
       "\n",
       "                       coverage_efficiency           EV_Pop_Gain_Pct  \\\n",
       "Strategy         Smart            Baseline     Smart                   \n",
       "N_Chargers                                                             \n",
       "10          118.285899            0.059217  0.066189       11.773469   \n",
       "25          311.259376            0.121831  0.177691       45.851068   \n",
       "50          536.529363            0.188903  0.299373       58.480026   \n",
       "\n",
       "           Demand_Gain_Pct  \n",
       "Strategy                    \n",
       "N_Chargers                  \n",
       "10               23.415068  \n",
       "25               55.813763  \n",
       "50               72.363118  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported CSVs for Tableau.\n"
     ]
    }
   ],
   "source": [
    "df_res = pd.DataFrame(results)\n",
    "\n",
    "# Pivot to compare side-by-side\n",
    "df_pivot = df_res.pivot(index='N_Chargers', columns='Strategy', values=['ev_population_served', 'unmet_demand_captured', 'coverage_efficiency'])\n",
    "\n",
    "# Calculate Efficiency Gains\n",
    "df_pivot['EV_Pop_Gain_Pct'] = (df_pivot[('ev_population_served', 'Smart')] - df_pivot[('ev_population_served', 'Baseline')]) / df_pivot[('ev_population_served', 'Baseline')] * 100\n",
    "df_pivot['Demand_Gain_Pct'] = (df_pivot[('unmet_demand_captured', 'Smart')] - df_pivot[('unmet_demand_captured', 'Baseline')]) / df_pivot[('unmet_demand_captured', 'Baseline')] * 100\n",
    "\n",
    "display(df_pivot)\n",
    "\n",
    "# Save Results\n",
    "# 1. Scenarios File\n",
    "df_locs_export = pd.DataFrame(locations_export)\n",
    "df_locs_export.to_csv('../data/processed/tableau_scenarios.csv', index=False)\n",
    "\n",
    "# 2. KPIs File\n",
    "df_kpis = df_res.copy()\n",
    "# Just simple flattening for Tableau\n",
    "df_kpis['Scenario_ID'] = df_kpis['Strategy'] + '_' + df_kpis['N_Chargers'].astype(str)\n",
    "df_kpis.to_csv('../data/processed/tableau_kpis.csv', index=False)\n",
    "\n",
    "# 3. Master Barrio File (ensure it has metrics)\n",
    "gdf_export = gdf.drop(columns=['geometry', 'centroid'], errors='ignore') # simple CSV for data attributes\n",
    "gdf_export.to_csv('../data/processed/tableau_barrios_master.csv', index=False)\n",
    "\n",
    "print(\"Exported CSVs for Tableau.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}